# EV Charging Reliability Mini‑Pipeline

This small project demonstrates how to build a simple data engineering pipeline
that resembles the kind of work you might perform at a company like
Terawatt Infrastructure.  It uses Python and built‑in libraries
(`pandas`, `sqlite3`, `matplotlib`) to generate synthetic charging session
data, process and enrich the data, load it into a star‑schema SQLite
database, and produce a basic reliability report.

The entire project can be executed locally.  It
covers several important concepts:

* **ETL/ELT pipelines** – reading raw data from CSV, transforming
  variables, calculating metrics and loading into a relational database.
* **Data modelling** – designing a very simple star schema with a fact table
  (`fact_charging`) and dimension tables (`dim_station`, `dim_time`).
* **Data quality and enrichment** – deriving session duration,
  calculating energy delivered per session, and computing reliability
  metrics (success rate) per station.
* **Reporting** – generating a bar chart that visualises the
  reliability of each station and saving the plot as a PNG file.

## Files

* **`ev_charging_pipeline.py`** – main script that runs the full
  pipeline.  It performs the following steps:
  1. Generate a synthetic dataset of charging sessions (optional – if a
     `charging_sessions.csv` file already exists, it will reuse it).
  2. Load the dataset into a pandas DataFrame and clean/transform
     columns (e.g., parse timestamps, compute durations).
  3. Create a simple SQLite database (`ev_charging.db`) and
     construct a star schema with dimension and fact tables.
  4. Populate the dimension tables and fact table with the processed
     data.
  5. Compute reliability metrics for each station and save the
     results as a bar chart (`station_reliability.png`).

* **`charging_sessions.csv`** – a synthetic dataset of 1 000 charging
  sessions generated by the script if it doesn’t already exist.  Each
  row contains a session ID, station ID, start/end timestamps,
  energy delivered (kWh) and whether the session succeeded.

* **`ev_charging.db`** – the SQLite database created by the script.

* **`station_reliability.png`** – an output plot showing the
  reliability (success rate) of each charging station.

## Usage

Ensure you have Python 3.10+ and the `pandas` library installed.  The
script will also attempt to import `matplotlib` to generate a plot.  If
`matplotlib` is unavailable, the script will still run the ETL tasks
and print the reliability results to the console.

```bash
python ev_charging_pipeline.py
```

After the script completes you should see the following artefacts in the
project directory:

* `charging_sessions.csv` – synthetic charging session data (if not
  previously present).
* `ev_charging.db` – SQLite database containing the star schema.
* `station_reliability.png` – bar chart of station reliability (if
  `matplotlib` is installed).

Reviewing the code will give you a sense of how to structure ETL
pipelines, design simple data models, compute metrics and generate
reports – all relevant skills for a data engineering interview.